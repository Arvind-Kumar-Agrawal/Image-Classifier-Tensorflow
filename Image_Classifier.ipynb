{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass_classification.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSiQa2F-wXVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "\n",
        "@author: Arvind Kumar\n",
        "\"\"\"\n",
        "import cv2 #reading and resizing                 \n",
        "import numpy as np #arrays         \n",
        "import os #dealing with directories                  \n",
        "from random import shuffle #to shuffle data\n",
        "from tqdm import tqdm #loop progress bar  \n",
        "from sklearn.metrics import roc_auc_score    \n",
        "import matplotlib.pyplot as plt # for visualizations\n",
        "import tensorflow as tf # For tensor operations\n",
        "import pandas as pd # for manipulating data\n",
        "import zipfile\n",
        "import os, sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bd_8zBU0Y00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install numpy==1.16.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqbWL8pawXVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "088a8d33-9f6a-4154-9178-748cbac7264e"
      },
      "source": [
        "#HYPERPARAMETERS\n",
        "# our photos are in the size of (80,80,3)\n",
        "IMG_SIZE = 80\n",
        "\n",
        "epochs = 5\n",
        "step_size = 8\n",
        "IMG_SIZE_ALEXNET = 227\n",
        "validating_size = 40\n",
        "nodes_fc1 = 4096\n",
        "nodes_fc2 = 4096\n",
        "output_classes = 4\n",
        "\n",
        "TRAIN_DIR = os.getcwd()\n",
        "\n",
        "#Current working directory\n",
        "\n",
        "print(TRAIN_DIR) # current working directory"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGC355gBwXVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzipping file\n",
        "with zipfile.ZipFile(\"datasets.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "#Reading .npy files\n",
        "train_data = np.load(os.path.join(os.getcwd(), 'datasets' ,'train_data_mc.npy'))\n",
        "test_data = np.load(os.path.join(os.getcwd(), 'datasets' ,'test_data_mc.npy'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sptn-uJ6wXVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In order to implement ALEXNET, we are resizing them to (227,227,3)\n",
        "for i in range(len(train_data)):\n",
        "    train_data[i][0] = cv2.resize(train_data[i][0],(IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET))\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    test_data[i][0] = cv2.resize(test_data[i][0],(IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET))\n",
        "\n",
        "train = train_data[:4800]\n",
        "cv = train_data[4800:]\n",
        "\n",
        "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3)\n",
        "Y = np.array([i[1] for i in train])\n",
        "\n",
        "cv_x = np.array([i[0] for i in cv]).reshape(-1,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3)\n",
        "cv_y = np.array([i[1] for i in cv])\n",
        "test_x = np.array([i[0] for i in test_data]).reshape(-1,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3)\n",
        "test_y = np.array([i[1] for i in test_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bp1QjirwXVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "59e705cf-ce4e-4622-be65-63ca42bb8dcc"
      },
      "source": [
        "print(X.shape)\n",
        "\n",
        "print(Y.shape)\n",
        "\n",
        "print(cv_x.shape)\n",
        "\n",
        "print(test_x.shape)\n",
        "\n",
        "steps = len(train)\n",
        "print(steps)\n",
        "remaining = steps % step_size"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4800, 227, 227, 3)\n",
            "(4800, 4)\n",
            "(400, 227, 227, 3)\n",
            "(1267, 227, 227, 3)\n",
            "4800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aIMUZmywXVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Resetting graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "#Defining Placeholders\n",
        "x = tf.placeholder(tf.float32,shape=[None,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3])\n",
        "y_true = tf.placeholder(tf.float32,shape=[None,output_classes])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQuVBEsuwXVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e3c69957-9ae0-4e7b-fa67-efd8ee0b4805"
      },
      "source": [
        "##CONVOLUTION LAYER 1\n",
        "#Weights for layer 1\n",
        "w_1 = tf.Variable(tf.truncated_normal([11,11,3,96], stddev=0.01))\n",
        "#Bias for layer 1\n",
        "b_1 = tf.Variable(tf.constant(0.0, shape=[[11,11,3,96][3]]))\n",
        "#Applying convolution\n",
        "c_1 = tf.nn.conv2d(x, w_1,strides=[1, 4, 4, 1], padding='VALID')\n",
        "#Adding bias\n",
        "c_1 = c_1 + b_1\n",
        "#Applying RELU\n",
        "c_1 = tf.nn.relu(c_1)\n",
        "print(c_1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Tensor(\"Relu:0\", shape=(?, 55, 55, 96), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGNUBcb1wXVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5103ce9-0379-49df-afce-4a95771b3acf"
      },
      "source": [
        "##POOLING LAYER1\n",
        "p_1 = tf.nn.max_pool(c_1, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
        "print(p_1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool:0\", shape=(?, 27, 27, 96), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN_0dm9QwXVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0c18eef-aa29-4ba0-c762-60da3b398bd2"
      },
      "source": [
        "##CONVOLUTION LAYER 2\n",
        "#Weights for layer 2\n",
        "w_2 = tf.Variable(tf.truncated_normal([5,5,96,256], stddev=0.01))\n",
        "#Bias for layer 2\n",
        "b_2 = tf.Variable(tf.constant(1.0, shape=[[5,5,96,256][3]]))\n",
        "#Applying convolution\n",
        "c_2 = tf.nn.conv2d(p_1, w_2,strides=[1, 1, 1, 1], padding='SAME')\n",
        "#Adding bias\n",
        "c_2 = c_2 + b_2\n",
        "#Applying RELU\n",
        "c_2 = tf.nn.relu(c_2)\n",
        "\n",
        "print(c_2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_1:0\", shape=(?, 27, 27, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbuWktyEwXVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6570ac87-e395-4366-da0d-56fdb59db151"
      },
      "source": [
        "##POOLING LAYER2\n",
        "p_2 = tf.nn.max_pool(c_2, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
        "print(p_2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool_1:0\", shape=(?, 13, 13, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-unkBSkdwXVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3235c32e-a0aa-4a42-f1ae-26d8e32040fd"
      },
      "source": [
        "##CONVOLUTION LAYER 3\n",
        "#Weights for layer 3\n",
        "w_3 = tf.Variable(tf.truncated_normal([3, 3, 256, 384], stddev=0.01))\n",
        "#Bias for layer 3\n",
        "b_3 = tf.Variable(tf.constant(0.0, shape=[[3, 3, 256, 384][3]]))\n",
        "#Applying convolution\n",
        "c_3 = tf.nn.conv2d(p_2, w_3,strides=[1, 1, 1, 1], padding='SAME')\n",
        "#Adding bias\n",
        "c_3 = c_3 + b_3\n",
        "#Applying RELU\n",
        "c_3 = tf.nn.relu(c_3)\n",
        "\n",
        "print(c_3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_2:0\", shape=(?, 13, 13, 384), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaLmHqORwXV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e63551f0-ae9e-4f1e-a6a2-79d856f5ba62"
      },
      "source": [
        "##CONVOLUTION LAYER 4\n",
        "#Weights for layer 4\n",
        "w_4 = tf.Variable(tf.truncated_normal([3, 3, 384, 384], stddev=0.01))\n",
        "#Bias for layer 4\n",
        "b_4 = tf.Variable(tf.constant(0.0, shape=[[3, 3, 384, 384][3]]))\n",
        "#Applying convolution\n",
        "c_4 = tf.nn.conv2d(c_3, w_4,strides=[1, 1, 1, 1], padding='SAME')\n",
        "#Adding bias\n",
        "c_4 = c_4 + b_4\n",
        "#Applying RELU\n",
        "c_4 = tf.nn.relu(c_4)\n",
        "\n",
        "print(c_4)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_3:0\", shape=(?, 13, 13, 384), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy1l1s7AwXV5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39e8bf64-4bdd-473c-fffa-c28d592ed880"
      },
      "source": [
        "##CONVOLUTION LAYER 5\n",
        "#Weights for layer 5\n",
        "w_5 = tf.Variable(tf.truncated_normal([3, 3, 384, 256], stddev=0.01))\n",
        "#Bias for layer 5\n",
        "b_5 = tf.Variable(tf.constant(0.0, shape=[[3, 3, 384, 256][3]]))\n",
        "#Applying convolution\n",
        "c_5 = tf.nn.conv2d(c_4, w_5,strides=[1, 1, 1, 1], padding='SAME')\n",
        "#Adding bias\n",
        "c_5 = c_5 + b_5\n",
        "#Applying RELU\n",
        "c_5 = tf.nn.relu(c_5)\n",
        "\n",
        "print(c_5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_4:0\", shape=(?, 13, 13, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irw3U4VXwXV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94267cc9-83ce-4eb9-ac79-1a7d7a8dd070"
      },
      "source": [
        "##POOLING LAYER3\n",
        "p_3 = tf.nn.max_pool(c_5, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
        "print(p_3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool_2:0\", shape=(?, 6, 6, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5qUxu9QwXWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b0cf7d6-2d20-4c4c-e68e-fca8383c2666"
      },
      "source": [
        "#Flattening\n",
        "flattened = tf.reshape(p_3,[-1,6*6*256])\n",
        "print(flattened)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Reshape:0\", shape=(?, 9216), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfzueAu4wXWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Fully Connected Layer 1\n",
        "#Getting input nodes in FC layer 1\n",
        "input_size = int( flattened.get_shape()[1] )\n",
        "#Weights for FC Layer 1\n",
        "w1_fc = tf.Variable(tf.truncated_normal([input_size, nodes_fc1], stddev=0.01))\n",
        "#Bias for FC Layer 1\n",
        "b1_fc = tf.Variable( tf.constant(1.0, shape=[nodes_fc1] ) )\n",
        "#Summing Matrix calculations and bias\n",
        "s_fc1 = tf.matmul(flattened, w1_fc) + b1_fc\n",
        "#Applying RELU\n",
        "s_fc1 = tf.nn.relu(s_fc1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d20s2-P_wXWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9650a62e-3d02-44f3-dd76-f1bd2518c96f"
      },
      "source": [
        "#Dropout Layer 1\n",
        "hold_prob1 = tf.placeholder(tf.float32)\n",
        "s_fc1 = tf.nn.dropout(s_fc1,keep_prob=hold_prob1)\n",
        "print(s_fc1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-f4a11912846c>:2: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"dropout/mul:0\", shape=(?, 4096), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ftFxj-wXWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d677e2d-5c15-4d36-bf8a-848a4a0b6847"
      },
      "source": [
        "##Fully Connected Layer 2\n",
        "#Weights for FC Layer 2\n",
        "w2_fc = tf.Variable(tf.truncated_normal([nodes_fc1, nodes_fc2], stddev=0.01))\n",
        "#Bias for FC Layer 2\n",
        "b2_fc = tf.Variable( tf.constant(1.0, shape=[nodes_fc2] ) )\n",
        "#Summing Matrix calculations and bias\n",
        "s_fc2 = tf.matmul(s_fc1, w2_fc) + b2_fc\n",
        "#Applying RELU\n",
        "s_fc2 = tf.nn.relu(s_fc2)\n",
        "print(s_fc2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_6:0\", shape=(?, 4096), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qaYrGv4wXWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dropout Layer 2\n",
        "hold_prob2 = tf.placeholder(tf.float32)\n",
        "s_fc2 = tf.nn.dropout(s_fc2,keep_prob=hold_prob1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30UtXGoqwXWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51f30370-c309-46ac-e293-f492a6dc250c"
      },
      "source": [
        "##Fully Connected Layer 3\n",
        "#Weights for FC Layer 3\n",
        "w3_fc = tf.Variable(tf.truncated_normal([nodes_fc2,output_classes], stddev=0.01))\n",
        "#Bias for FC Layer 3b3_fc = tf.Variable( tf.constant(1.0, shape=[output_classes] ) )\n",
        "b3_fc = tf.Variable( tf.constant(1.0, shape=[output_classes] ) )\n",
        "#Summing Matrix calculations and bias\n",
        "y_pred = tf.matmul(s_fc2, w3_fc) + b3_fc\n",
        "#Applying RELU\n",
        "print(y_pred)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"add_7:0\", shape=(?, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSH_sv-3wXWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining loss function\n",
        "\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))\n",
        "\n",
        "#Defining objective\n",
        "train = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(cross_entropy)\n",
        "\n",
        "#Defining Accuracy\n",
        "matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "\n",
        "#Initializing weights\n",
        "init = tf.global_variables_initializer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0S4rrqCwXWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Starting Empty lists to keep results\n",
        "acc_list = []\n",
        "auc_list = []\n",
        "loss_list = []\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvzo2L52wXWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GPU settings\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "config.gpu_options.allow_growth = True\n",
        "config.gpu_options.allocator_type = 'BFC'\n",
        "with tf.Session(config=config) as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(epochs):\n",
        "        for j in range(0,steps-remaining,step_size):\n",
        "            #Feeding step_size-amount data with 0.5 keeping probabilities on DROPOUT LAYERS\n",
        "            _,c = sess.run([train,cross_entropy],\n",
        "\t\t\tfeed_dict={x:X[j:j+step_size] , y_true:Y[j:j+step_size],hold_prob1:0.5,hold_prob2:0.5})\n",
        "        \n",
        "        \n",
        "\t\t#Writing for loop to calculate test statistics. GTX 1050 isn't able to calculate all test data.\n",
        "        cv_auc_list = []\n",
        "        cv_acc_list = []\n",
        "        cv_loss_list = []\n",
        "        for v in range(0,len(cv_x)-int(len(cv_x) % validating_size),validating_size):\n",
        "            acc_on_cv,loss_on_cv,preds = sess.run([acc,cross_entropy,tf.nn.softmax(y_pred)],\n",
        "\t\t\tfeed_dict={x:cv_x[v:v+validating_size] ,y_true:cv_y[v:v+validating_size] ,hold_prob1:1.0,hold_prob2:1.0})\n",
        "\t\t\t\n",
        "            auc_on_cv = roc_auc_score(cv_y[v:v+validating_size],preds)\n",
        "            cv_acc_list.append(acc_on_cv)\n",
        "            cv_auc_list.append(auc_on_cv)\n",
        "            cv_loss_list.append(loss_on_cv)\n",
        "        acc_cv_ = round(np.mean(cv_acc_list),5)\n",
        "        auc_cv_ = round(np.mean(cv_auc_list),5)\n",
        "        loss_cv_ = round(np.mean(cv_loss_list),5)\n",
        "        acc_list.append(acc_cv_)\n",
        "        auc_list.append(auc_cv_)\n",
        "        loss_list.append(loss_cv_)\n",
        "        print(\"Epoch:\",i,\"Accuracy:\",acc_cv_,\"Loss:\",loss_cv_ ,\"AUC:\",auc_cv_)\n",
        "    \n",
        "    test_auc_list = []\n",
        "    test_acc_list = []\n",
        "    test_loss_list = []\n",
        "    for v in range(0,len(test_x)-int(len(test_x) % validating_size),validating_size):\n",
        "        acc_on_test,loss_on_test,preds = sess.run([acc,cross_entropy,tf.nn.softmax(y_pred)],\n",
        "\t\tfeed_dict={x:test_x[v:v+validating_size] ,y_true:test_y[v:v+validating_size] ,hold_prob1:1.0,hold_prob2:1.0})\n",
        "        \n",
        "        auc_on_test = roc_auc_score(test_y[v:v+validating_size],preds)\n",
        "        test_acc_list.append(acc_on_test)\n",
        "        test_auc_list.append(auc_on_test)\n",
        "        test_loss_list.append(loss_on_test)\n",
        "    saver.save(sess, os.path.join(os.getcwd(),\"CNN_MC.ckpt\"))\n",
        "    test_acc_ = round(np.mean(test_acc_list),5)\n",
        "    test_auc_ = round(np.mean(test_auc_list),5)\n",
        "    test_loss_ = round(np.mean(test_loss_list),5)\n",
        "    print(\"Test Results are below:\")\n",
        "    print(\"Accuracy:\",test_acc_,\"Loss:\",test_loss_,\"AUC:\",test_auc_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5vz9iQqwXWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f,ax=plt.subplots(1,3,figsize=(12,3))\n",
        "pd.Series(acc_list).plot(kind='line',title='Accuracy on CV data',ax=ax[0])\n",
        "pd.Series(loss_list).plot(kind='line',figsize=(12,7),title='Loss on CV data',ax=ax[1])\n",
        "pd.Series(auc_list).plot(kind='line',figsize=(12,7),title='AUC on CV data',ax=ax[2])\n",
        "plt.subplots_adjust(wspace=0.8)\n",
        "ax[0].set_title('Accuracy on CV data')\n",
        "ax[1].set_title('Loss on CV data')\n",
        "ax[2].set_title('AUC on CV data')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY-JrR_YwXWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Restoring a pretrained\n",
        "with tf.Session() as session:\n",
        "    saver.restore(session, \"CNN_MC.ckpt\")\n",
        "    print(\"Model restored.\") \n",
        "    print('Initialized')\n",
        "    k = session.run([tf.nn.softmax(y_pred)], feed_dict={x:test_x[0:64] , hold_prob1:1,hold_prob2:1})\n",
        "\n",
        "print(np.array(k).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aes8lQ5wXWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping k\n",
        "k = np.array(k).reshape(64,output_classes)\n",
        "\n",
        "print(k[0])\n",
        "\n",
        "pred_labels = []\n",
        "\n",
        "for i in range(64):\n",
        "    r = np.round(k[i],3).argmax()\n",
        "    if r ==0 : pred_labels.append(\"chair\")\n",
        "    elif r ==1: pred_labels.append(\"kitchen\")\n",
        "    elif r ==2: pred_labels.append(\"knife\")\n",
        "    elif r ==3: pred_labels.append(\"saucepan\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj_fQUzvwXWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Multiple images parameters\n",
        "w=80\n",
        "h=80\n",
        "columns = 8\n",
        "rows = 8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFiTvKvIwXW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#First 64 images\n",
        "images = test_x[:64]\n",
        "\n",
        "print(images.shape)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "for m in range(1, columns*rows +1):\n",
        "    img = images[m-1].reshape([IMG_SIZE_ALEXNET, IMG_SIZE_ALEXNET, 3])\n",
        "    fig.add_subplot(rows, columns, m)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Pred: \" + pred_labels[m-1])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W5LWHO1wXW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5witv6PUwXW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}